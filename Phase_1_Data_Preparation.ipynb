{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BI1OoHKVfkd3"
      },
      "source": [
        "Dowloading and Isntalling dependencies of spark in the next three coding blocks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdgLslbsQNfQ"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRCBD5xoQtgE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "Y3F3lSuOQxFo",
        "outputId": "94720bae-9b86-4075-e3a0-8f574c6dafad"
      },
      "outputs": [],
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True) # Property used to format output tables better\n",
        "spark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0ZPd9I-gBOf"
      },
      "source": [
        "Doing imports required"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzBb5qcT9MHk",
        "outputId": "2b6bbeed-a6c3-4dda-f75d-313d023c965f"
      },
      "outputs": [],
      "source": [
        "!pip install -U imbalanced-learn\n",
        "!pip install seaborn\n",
        "from pyspark.sql.functions import col, expr, when\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "import matplotlib.pyplot as plt \n",
        "import matplotlib as mpl\n",
        "import matplotlib.dates as mdates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obcNvnUHgOjH"
      },
      "source": [
        "Reading the contents of the json file, Please paste your link/address here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xd36cPpvQ07v"
      },
      "outputs": [],
      "source": [
        "# Please paste the file link here.\n",
        "DF = spark.read.json('/content/sample.json')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AacSayQvgfct"
      },
      "source": [
        "Identifying the Important Attributes for the class labeling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P168QSCcAbCw"
      },
      "outputs": [],
      "source": [
        "imp_Attributes = ['DownloadSpeed','UploadSpeed','Ping','TTFB']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TREPGqa7g8h-"
      },
      "source": [
        "Defining Function to calculate Median. Finding medians of required attributes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgLKzA6xg1MR"
      },
      "outputs": [],
      "source": [
        "def calculate_Median(tdf,At):\n",
        "  tdf = tdf.select(At)\n",
        "  tdf = tdf.na.drop(subset=[At])\n",
        "  count = tdf.count()\n",
        "  tdf = tdf.sort(At)\n",
        "  if count % 2 ==0:\n",
        "    Median = (tdf.select(At).collect()[int(count/2)][0] + tdf.select(At).collect()[int(count/2)-1][0])/2\n",
        "  else:\n",
        "    Median = tdf.select(At).collect()[int((count-1)/2)][0]\n",
        "  return Median\n",
        "\n",
        "Med_DNS = calculate_Median(DF,imp_Attributes[0])\n",
        "Med_UPS = calculate_Median(DF,imp_Attributes[1])\n",
        "Med_Ping = calculate_Median(DF,imp_Attributes[2])\n",
        "Med_TTFB = calculate_Median(DF,imp_Attributes[3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-ZR8MO9HD3a",
        "outputId": "e2b524b8-9f6e-4c37-f637-948319e84393"
      },
      "outputs": [],
      "source": [
        "print (' Median DNS: ',Med_DNS,\"\\n\",'Median UPS: ',Med_UPS,\"\\n\",'Median Ping: ',Med_Ping,\"\\n\",'Median TTFB: ',Med_TTFB )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjWNlhQLhONJ"
      },
      "source": [
        "All the Attributes to be used are defined here in this list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8o4wYJx0Bmc"
      },
      "outputs": [],
      "source": [
        "Attributes = ['Latitude','Longitude','@timestamp','Manufacturer','Model','AppName','SdkVersion','AppVersion',\n",
        "              'AndroidApi','OSVersion','ActiveConnection','WifiBSSID','WifiRssi','WifiLinkSpeed',\n",
        "              'lvl1_name','IP','ASN','ISP','URL','dnsLookup','initialConnection','sslNegotiation',\n",
        "              'TTFB','fullyLoaded','PageloadSpeed','loadEventEnd','documentComplete','Ping',\n",
        "              'DownloadSpeed','UploadSpeed','LteRssi','WcdmaRssi','GsmRssi']\n",
        "# Attributes = ['location','@timestamp','Manufacturer','Model','AppName','SdkVersion','AppVersion',\n",
        "#               'AndroidApi','OSVersion','ActiveConnection','WifiBSSID','WifiRssi','WifiLinkSpeed',\n",
        "#               'lvl1_name','IP','ASN','ISP','URL','dnsLookup','initialConnection','sslNegotiation',\n",
        "#               'TTFB','fullyLoaded','PageloadSpeed','loadEventEnd','documentComplete','Ping',\n",
        "#               'DownloadSpeed','UploadSpeed','LteRssi','WcdmaRssi','GsmRssi']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p--yicAb0ZU0"
      },
      "outputs": [],
      "source": [
        "df = DF.select(Attributes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZClwwkqhfNf"
      },
      "source": [
        "Visualizing the Attributes in our data to make sure we are using required ones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-v1WO8F0-Uc",
        "outputId": "02649129-90a0-4f8e-c979-d93c1a58285e"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgO9FWZLhzH6"
      },
      "source": [
        "Removing Duplicates from the dataset samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgX217GKUNDH",
        "outputId": "044a4cfa-90e5-4260-afbf-6a1e2398438e"
      },
      "outputs": [],
      "source": [
        "print(\"Checking and Removing Duplicates\\n\",\"Samples before removing:\",df.count())\n",
        "df = df.distinct()\n",
        "print(\"Samples after removing Duplicates:\",df.count())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S26-CwDth9ZI"
      },
      "source": [
        "Defining the Attributes according to the Action required for NULL values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktFbDRNu3isX"
      },
      "outputs": [],
      "source": [
        "Record_Removing_Attributes = ['Latitude','Longitude','@timestamp','AppName','SdkVersion','AppVersion','AndroidApi','OSVersion','ActiveConnection','lvl1_name','IP','ASN','ISP','URL','Manufacturer','Model']\n",
        "Assign_Zero_Attributes_str = ['WifiBSSID','WifiRssi']\n",
        "Assign_Zero_Attributes = ['WifiLinkSpeed','dnsLookup','initialConnection','sslNegotiation',\n",
        "                         'fullyLoaded','PageloadSpeed','loadEventEnd','documentComplete','LteRssi','WcdmaRssi','GsmRssi']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAdBNLAQzDFi"
      },
      "source": [
        "Droping rows of NULL values against record removing attributes and with google URL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlwNoTGiSXBq",
        "outputId": "b03ee4ea-5065-433f-f7a6-c308ab1927b6"
      },
      "outputs": [],
      "source": [
        "df = df.na.drop(subset=Record_Removing_Attributes)\n",
        "df = df[df.ActiveConnection != \"\"] # There were some values in this coulum that were empty but not assigned NULL position.\n",
        "df=df.where(df.URL !=\"https://www.google.com.bh\")\n",
        "print(\"Truncated df count will be :\", df.count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 968
        },
        "id": "P4v48nGw9H6j",
        "outputId": "29af552d-cc63-4566-d30b-062a913e4f65"
      },
      "outputs": [],
      "source": [
        "print('Before replacing values')\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzccQ39vzi2j"
      },
      "source": [
        "Replacement of NULL values with 0 and Medians accordingly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 968
        },
        "id": "l2sFzAi--NAS",
        "outputId": "4bed3296-58dd-4258-fc68-bb8bedec6604"
      },
      "outputs": [],
      "source": [
        "df = df.fillna(value = Med_DNS ,subset = imp_Attributes[0])\n",
        "df = df.fillna(value = Med_UPS ,subset = imp_Attributes[1])\n",
        "df = df.fillna(value = Med_Ping ,subset = imp_Attributes[2])\n",
        "df = df.fillna(value = Med_TTFB ,subset = imp_Attributes[3])\n",
        "df = df.fillna(value=0,subset=Assign_Zero_Attributes)\n",
        "df = df.fillna(value='0',subset=Assign_Zero_Attributes_str)\n",
        "print('After replacing values')\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUqjYGSLz9yf"
      },
      "source": [
        "Counting Acceptable values in data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFQATYjcOxdS",
        "outputId": "abd3d4e1-7c52-4f9f-f7ca-b9c125e80938"
      },
      "outputs": [],
      "source": [
        "df.where((df.DownloadSpeed >= 1.5) & (df.UploadSpeed >= 0.5) & (df.Ping <=20) & (df.TTFB <=1200)).count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZ_mRbWnDDyj"
      },
      "source": [
        "Adding QoE Coulum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnzBoWQwV4eq"
      },
      "outputs": [],
      "source": [
        "df3 = df.withColumn(\"QoE\", when(((df.DownloadSpeed >= 1.5) & (df.UploadSpeed >= 0.5) & (df.Ping <=20) & (df.TTFB <=1200)),1)\n",
        "                                 .otherwise(0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBPuIXpE80uM"
      },
      "source": [
        "Understanding the storage type of data inside the coulums"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhYQ-fijbNtC",
        "outputId": "4e389c04-9283-4fcf-c329-cce6d3af890c"
      },
      "outputs": [],
      "source": [
        "df3.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YT59sDPxAFnq"
      },
      "source": [
        "Extracting name of coulums containing string data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-A0b4JJGb16z"
      },
      "outputs": [],
      "source": [
        "String_Cols = [item[0] for item in df3.dtypes if item[1].startswith('string')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtCpjKQCim7s",
        "outputId": "c0c6c0c6-de3b-456a-c484-653fb5a1efa1"
      },
      "outputs": [],
      "source": [
        "print(String_Cols)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bxEPqbWARhM"
      },
      "source": [
        "'gdf' contains frequency of each type of entry in string data frames."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6o3Ra-YzcAKo"
      },
      "outputs": [],
      "source": [
        "gdf = pd.DataFrame()\n",
        "for x in String_Cols:\n",
        "  t = df3.groupBy(x).count().toPandas()\n",
        "  gdf = pd.concat([gdf,t],axis = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnoJcJovArHu"
      },
      "source": [
        "Saving Frequency information of string coulums in \"String_Frequency.csv\" file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rg1035PQyEn8"
      },
      "outputs": [],
      "source": [
        "gdf.to_csv('/content/String_Frequency.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIRKNXUEA_Mg"
      },
      "source": [
        "Saving actual data after Cleansing to \"After_Cleansing.csv\" file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLVDW2p77Au0"
      },
      "outputs": [],
      "source": [
        "pdf = df3.toPandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_Xqx1KwYD6g"
      },
      "outputs": [],
      "source": [
        "pdf.to_csv('/content/After_Cleansing.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_Gq-hfnBfxg"
      },
      "source": [
        "It is saving the description of Data Distribution of all the coulums to \"Distribution.csv\" file "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DPOdN27x7zoO"
      },
      "outputs": [],
      "source": [
        "pdf.describe(include='all').to_csv('/content/Distribution.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fgg02C-sCJJV"
      },
      "source": [
        "Code for using ADASYN technique of Oversampling for Data Balancing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QzDWuOjBKV2-"
      },
      "outputs": [],
      "source": [
        "def makeOverSamplesADASYN(X,y):\n",
        " #input DataFrame\n",
        " #X →Independent Variable in DataFrame\\\n",
        " #y →dependent Variable in Pandas DataFrame format\n",
        " from imblearn.over_sampling import ADASYN \n",
        " sm = ADASYN()\n",
        " X, y = sm.fit_resample(X, y)\n",
        " return(X,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQaF4LZqIVis"
      },
      "outputs": [],
      "source": [
        "P_df = df.select(imp_Attributes).toPandas()\n",
        "Y_df = df3.select('QoE').toPandas()\n",
        "P_df,Y_df = makeOverSamplesADASYN(P_df,Y_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yWvWZ5PWw-HF"
      },
      "outputs": [],
      "source": [
        "result = pd.concat([P_df,Y_df])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNl40uaW0Ulq"
      },
      "outputs": [],
      "source": [
        "result.to_csv('/content/After_ADASYN.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85YHFoJ3DP7T"
      },
      "source": [
        "Sample code for multi conditional work on spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sxE9T2dYwSxc"
      },
      "outputs": [],
      "source": [
        "# df2 = df.withColumn(\"QoE\", when(((df.DownloadSpeed >= 1.5) & (df.DownloadSpeed < 5) & (df.UploadSpeed >= 0.5) & (df.UploadSpeed < 1.5) & (df.Ping >50)& (df.Ping <=100) & (df.TTFB >800)& (df.TTFB <=1200)) ,\"A\")\n",
        "#                                  .when((df.DownloadSpeed >= 5) & (df.UploadSpeed >= 1.5) & (df.Ping <=50) & (df.TTFB <=800),\"E\")\n",
        "#                                  .otherwise(\"NA\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaohhSx4E-2Y"
      },
      "source": [
        "Code for removing Outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "T68_-5vrAkN4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "df = df[(np.abs(stats.zscore(df)) < 3).all(axis=1)]  # Will remove outliers 3 Standard Deviations from mean"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pn7MVE_LFn0x"
      },
      "source": [
        "Code for Normalization of values in the data frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEcJ4d_VFCLl"
      },
      "outputs": [],
      "source": [
        "# copy the data\n",
        "df_min_max_scaled = df.copy()\n",
        "  \n",
        "# apply normalization techniques\n",
        "for column in df_min_max_scaled.columns:\n",
        "    df_min_max_scaled[column] = (df_min_max_scaled[column] - df_min_max_scaled[column].min()) / (df_min_max_scaled[column].max() - df_min_max_scaled[column].min())  "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
